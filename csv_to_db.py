"""converts the csv files generated by other scripts into sqlite tables"""

from config import year
from statcast import index_pitches
import fangraphs
import retrosheet

# Import required libraries
import os
import sqlite3
import pandas as pd

import retrosheet

from table_definitions import *

def drop_table(name):
    conn.execute(f"DROP TABLE IF EXISTS \"{name}\"")

pitches_created = False

class DataSource:
    def __init__(self, path, table_name, definition, index=False, has_header=True, names=None, extra_setup=lambda conn: None):
        self.path = path
        self.table_name = table_name
        self.definition = definition
        self.index = index
        self.has_header = has_header
        self.names = names
        self.extra_setup = extra_setup

statcast_ds = DataSource(f"{year}_statcast_cleaned.csv", "statcast_pitches", pitch_definition, index_pitches, "pitch_index", lambda conn: conn.execute('CREATE INDEX idx_pitches_game_pk ON statcast_pitches(game_pk);'))
chadwick_ds = DataSource("chadwick_register.csv", "chadwick", chadwick_definition)
bref_batting_ds = DataSource(f"bref_batting_{year}.csv", "bref_batting", bref_batting_definition)
bref_pitching_ds = DataSource(f"bref_pitching_{year}.csv", "bref_pitching", bref_pitching_definition)
fangraphs_batting_ds = DataSource(fangraphs.batter_data_file, "fangraphs_batting", fangraphs_batting_definition)
fangraphs_pitching_ds = DataSource(fangraphs.pitcher_data_file, "fangraphs_pitching", fangraphs_pitching_definition)
fangraphs_fielding_ds = DataSource(fangraphs.fielder_data_file, "fangraphs_fielding", fangraphs_fielding_definition)
fangraphs_team_batting_ds = DataSource(fangraphs.team_batting_data_file, "fangraphs_team_batting", fangraphs_team_batting_definition)
fangraphs_team_pitching_ds = DataSource(fangraphs.team_pitching_data_file, "fangraphs_team_pitching", fangraphs_team_pitching_definition)
fangraphs_team_fielding_ds = DataSource(fangraphs.team_fielding_data_file, "fangraphs_team_fielding", fangraphs_team_fielding_definition)
retrosheet_game_log_ds = DataSource(retrosheet.game_log_file, "retrosheet_game_logs", retrosheet_game_log_definition, index=True, has_header=False, names=retrosheet.game_log_columns)
retrosheet_park_ds = DataSource(retrosheet.park_codes_file, "retrosheet_park_codes", retrosheet_park_definition)
retrosheet_team_ds = DataSource(retrosheet.teams_file, "retrosheet_teams", retrosheet_team_definition, has_header = False, names=retrosheet.teams_columns)

# TODO: make a better way to configure this
data_sources = [
    statcast_ds,
    chadwick_ds,
    bref_batting_ds,
    bref_pitching_ds,
    fangraphs_batting_ds,
    fangraphs_pitching_ds,
    fangraphs_fielding_ds,
    fangraphs_team_batting_ds,
    fangraphs_team_pitching_ds,
    fangraphs_team_fielding_ds,
    retrosheet_game_log_ds,
    retrosheet_park_ds,
    retrosheet_team_ds
]

db_file = f"{year}_baseball.db"

for ds in data_sources:
    if os.path.exists(ds.path):
        ds.exists = True
        print(f"  Found {ds.table_name} CSV: {ds.path}")
    else:
        ds.exists = False
        print(f"  MISSING {ds.table_name} CSV: {ds.path}")


print("Connecting to database...")
conn = sqlite3.connect(db_file)

for ds in data_sources:
    if ds.exists:
        print(f"  Reading {ds.table_name} CSV: {ds.path}")
        if not ds.has_header:
            df = pd.read_csv(ds.path,header=None, names=ds.names)
        else:
            df = pd.read_csv(ds.path)
        drop_table(ds.table_name)
        conn.execute(ds.definition)
        df.to_sql(ds.table_name, conn, if_exists='append', index=ds.index, index_label="idx")
        ds.extra_setup(conn)
        print(f"  {ds.table_name} written to database")
    else:
        print(f"  skipping {ds.table_name}")

# Close the connection
print("Closing connection to database.")
conn.close()

print(f"Finished writing available data to {db_file}")
